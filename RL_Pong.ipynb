{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies\n",
        "The initial cells ensure that the necessary Python libraries are installed. These include:\n",
        "\n",
        "- `numpy` for numerical computations\n",
        "- `matplotlib` for visualization\n",
        "- `gymnasium` for simulating the Pong environment\n",
        "- `ale-py` for Atari Learning Environment (ALE) support\n",
        "\n",
        "\n",
        "These installations allow the notebook to run reinforcement learning experiments using the Pong game environment.\n"
      ],
      "metadata": {
        "id": "47AvhsJwFMQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjw88-itrQjt",
        "outputId": "da60199f-14e1-40a4-ad2a-bf4424e4038a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari,accept-rom-license] --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXc6PvJM-sno",
        "outputId": "1f57eebb-820d-4a10-c13a-d3ea24e8cb10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "\u001b[33mWARNING: gymnasium 1.1.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[accept-rom-license,atari]) (0.10.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if needed (uncomment the next line)\n",
        "# !pip install gym torch numpy matplotlib\n",
        "!pip install ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJuqq5i-0fnz",
        "outputId": "05c5a621-fbeb-4c5d-83ba-74e13548b7a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autorom[accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihr9csDhL1GU",
        "outputId": "1d09d9e1-f3ad-4fe7-9b5c-8e317ed362d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.1.31)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446711 sha256=582b552f65d7f556f54b343d5f1b8a57e206ed46beefcc3088894dae37701818\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install atari_py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nYxwfu8MGhW",
        "outputId": "448eccbe-6bb1-45fd-a90d-c6eb541dfade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting atari_py\n",
            "  Downloading atari-py-0.2.9.tar.gz (540 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/540.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m430.1/540.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.6/540.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari_py) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from atari_py) (1.17.0)\n",
            "Building wheels for collected packages: atari_py\n",
            "  Building wheel for atari_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atari_py: filename=atari_py-0.2.9-cp311-cp311-linux_x86_64.whl size=2871997 sha256=13b0c8bbeb651d914f577540f32723ff0cc1e88fa064413e8835e5beacbab38c\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/bb/c9/355a2560e9a75e6800cd54c37a19ca22badc1cf6a8b4a34c1b\n",
            "Successfully built atari_py\n",
            "Installing collected packages: atari_py\n",
            "Successfully installed atari_py-0.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ale-py\n",
        "!pip install autorom[accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nllMJQJrNNTF",
        "outputId": "206f031d-787a-47a8-b7dd-e0fdef7e252d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.11/dist-packages (from ale-py) (2.0.2)\n",
            "Requirement already satisfied: autorom[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay\n",
        "!apt-get install -y xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W3bYoya_5g-",
        "outputId": "c8aa7543-49a8-447b-df3c-1b52c925965b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 7,814 kB of archives.\n",
            "After this operation, 12.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.13 [29.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.13 [863 kB]\n",
            "Fetched 7,814 kB in 1s (7,644 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.13_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.13_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.13) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Libraries\n",
        "After installing dependencies, the script imports necessary modules:\n",
        "\n",
        "- `gymnasium` provides the Pong environment.\n",
        "- `numpy` is used for numerical operations.\n",
        "- `matplotlib.pyplot` is used for visualization.\n",
        "- `torch`, `torch.nn`, and `torch.optim` are used for implementing the neural network model and optimization.\n",
        "\n"
      ],
      "metadata": {
        "id": "14pG4E50CLbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 1: Setup and Dependencies\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import random\n",
        "import atari_py  # Import atari_py to register the Atari environments\n",
        "import ale_py # import ale_py package"
      ],
      "metadata": {
        "id": "LYLPvsMi7qbk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up the Pong Environment\n",
        "\n",
        "The script initializes the Pong environment using `gym.make()`:\n",
        "\n",
        "- The environment is created using `ALE/Pong-v5`.\n",
        "- `render_mode='rgb_array'` ensures that the environment renders frames as images.\n",
        "- `env.action_space.n` retrieves the number of possible actions the agent can take in the game.\n",
        "\n"
      ],
      "metadata": {
        "id": "0HRS794UCkeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize environment\n",
        "\n",
        "env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\") # Changed environment ID"
      ],
      "metadata": {
        "id": "ZDiniK9SKmaW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Observation space:\", env.observation_space.shape)  # (210, 160, 3)\n",
        "print(\"Action space:\", env.action_space.n)  # 6 actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2ZHP2EALIm_",
        "outputId": "7ff4a198-7c77-42c3-da6a-3c3c21b8bfea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation space: (210, 160, 3)\n",
            "Action space: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Deep Q-Network (DQN)\n",
        "\n",
        "A neural network is used to approximate the Q-function, which estimates the expected reward for each action.\n",
        "\n",
        "- Uses convolutional layers to extract spatial features.\n",
        "- Fully connected layers map the extracted features to action values.\n",
        "\n"
      ],
      "metadata": {
        "id": "JUIPTM7vD22_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 2: Define the Neural Network\n",
        "\n",
        "# Define CNN-based DQN Model\n",
        "class CNN_DQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(CNN_DQN, self).__init__()\n",
        "\n",
        "        # Define Convolutional Layers\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, kernel_size=8, stride=4),  # Output: (32, 20, 20)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),  # Output: (64, 9, 9)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),  # Output: (64, 7, 7)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        # The output from the last convolution layer has the size: (64, 7, 7), so the input size to the fully connected layer should be 64*7*7\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 512),  # Flattening (64 * 7 * 7 = 3136)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)  # Output size: num_actions (number of possible actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)  # Apply convolutional layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output to (batch_size, 3136)\n",
        "        return self.fc_layers(x)  # Pass through fully connected layers\n"
      ],
      "metadata": {
        "id": "l1ej-WwTldSu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize policy and target networks\n",
        "policy_net = CNN_DQN(env.observation_space.shape, env.action_space.n)\n",
        "target_net = CNN_DQN(env.observation_space.shape, env.action_space.n)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Exploration parameters\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.05\n",
        "gamma = 0.99\n",
        "\n",
        "# Experience Replay\n",
        "replay_memory = deque(maxlen=100000)\n",
        "\n"
      ],
      "metadata": {
        "id": "tHKf_xt9KqOh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Frames\n",
        "\n",
        "To simplify input to the neural network, frames are converted to grayscale and resized:\n",
        "\n",
        "- Crops the frame to remove unnecessary areas.\n",
        "- Converts the frame to grayscale by averaging color channels.\n",
        "- Downsamples the image to reduce computational complexity.\n"
      ],
      "metadata": {
        "id": "lWpWjODXHSKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess frames\n",
        "import cv2\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    frame = cv2.resize(frame, (84, 84))  # Resize\n",
        "    return frame / 255.0  # Normalize\n",
        "\n",
        "# Function to stack frames\n",
        "def stack_frames(frames, new_frame, is_new=False):\n",
        "    processed_frame = preprocess_frame(new_frame)\n",
        "    if is_new:\n",
        "        return np.stack([processed_frame] * 4, axis=0)\n",
        "    else:\n",
        "        frames[:-1] = frames[1:]  # Shift frames left\n",
        "        frames[-1] = processed_frame\n",
        "        return frames\n"
      ],
      "metadata": {
        "id": "bfHue8gfKqIL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# This is specific to the pong environment\n",
        "def img_crop(img):\n",
        "    return img[30:-12,:,:]\n",
        "\n",
        "# GENERAL Atari preprocessing steps\n",
        "def downsample(img):\n",
        "    # We will take only half of the image resolution\n",
        "    return img[::2, ::2]\n",
        "\n",
        "def transform_reward(reward):\n",
        "    return np.sign(reward)\n",
        "\n",
        "def to_grayscale(img):\n",
        "    return np.mean(img, axis=2).astype(np.uint8)\n",
        "\n",
        "# Normalize grayscale image from -1 to 1.\n",
        "def normalize_grayscale(img):\n",
        "    return (img - 128) / 128 - 1\n",
        "\n",
        "def process_frame(img, image_shape):\n",
        "    img = img_crop(img)\n",
        "    img = downsample(img)    # Crop and downsize (by 2)\n",
        "    img = to_grayscale(img)       # Convert to greyscale by averaging the RGB values\n",
        "    img = normalize_grayscale(img)  # Normalize from -1 to 1.\n",
        "\n",
        "    return np.expand_dims(img.reshape(image_shape[0], image_shape[1], 1), axis=0)"
      ],
      "metadata": {
        "id": "NP74j0gYKqFg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\") # Changed environment ID\n",
        "obs, _ = env.reset()\n"
      ],
      "metadata": {
        "id": "Dzt-CnNHVevn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "ac5Y_29UVzn2",
        "outputId": "a300331a-e80e-4341-d1f2-68da9153597b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       [[109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       [[109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]],\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]],\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-4ed320ac-46ea-453c-8c22-3b58ed48e1bc\" class=\"ndarray_repr\"><pre>ndarray (210, 160, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACh0lEQVR4nO3bPUoDURhAUSMD2lu4CDdgaZeVWNq6GVeSzjIbcBEp0sfOJsg0EgPODLmeUwXyMw8uHw/mTVZXP3h5ffjpLS7Ias6Qz0+nr/X2/jHDSuZx+Nyc/MztzXrSNVxP+ussTuA4geOGpS483mt/szdfuvFe+5u9+a+Y4DiB4wSOEzhO4DiB4wSOEzhO4DiB4wSOW+xe9H+4/zw25/3nMRMcJ3CcwHGzPpPF/ExwnMBxw3a3X3oNTMgExwkcJ3CcwHECxwkcJ3CcwHECxw2P93dLr4EJmeA4geMEjhM4TuA4geMEjhM4TuA4geOOgbe7vafvkkxwnMBxAscd/x/s0LDKBMcJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHDcsvQBOO3xuvl/f3qzP+q4JjhM4TuA4geMEjhM4TuA4geMEjhM4TuA4geMEjhM4TuA458EX4Nwz4DETHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHDdsd/ul18CETHCcwHECxwkcJ3CcwHECxwkcJ3CcwHECxwkcJ3CcwHECx30Bu1ci6JJ73gAAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       [[109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       [[109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        ...,\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43],\n",
              "        [109, 118,  43]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]],\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]],\n",
              "\n",
              "       [[ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        ...,\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24],\n",
              "        [ 53,  95,  24]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-4ed320ac-46ea-453c-8c22-3b58ed48e1bc button').onclick = (e) => {\n",
              "        document.querySelector('#id-4ed320ac-46ea-453c-8c22-3b58ed48e1bc').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-4ed320ac-46ea-453c-8c22-3b58ed48e1bc button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_obs = process_frame(obs, (84, 80))  # Process the image"
      ],
      "metadata": {
        "id": "zSqBKTg9VetB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "# Initialize 4-frame stack\n",
        "frame_stack = deque([processed_obs] * 4, maxlen=4)\n",
        "\n",
        "# Convert stack to NumPy array for CNN input\n",
        "stacked_state = np.array(frame_stack).reshape(1, 84, 80, 4)\n"
      ],
      "metadata": {
        "id": "tcNaa6AgVeqe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Original Frame\n",
        "ax[0].imshow(obs)\n",
        "ax[0].set_title(\"Original Frame (RGB)\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "# Processed Frame\n",
        "ax[1].imshow(stacked_state.squeeze(), cmap=\"gray\")\n",
        "ax[1].set_title(\"Processed Frame (Grayscale)\")\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "yJ1yPqFFVelc",
        "outputId": "ba935c97-2121-4398-f5d3-880186d8666d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.859375..0.703125].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Rewards"
      ],
      "metadata": {
        "id": "EXBoY261HFY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_reward(obs, reward, done, info):\n",
        "    \"\"\"\n",
        "    Calculates a custom reward based on game events.\n",
        "\n",
        "    Args:\n",
        "        obs (np.ndarray): The current observation of the environment.\n",
        "        reward (float): The original reward from the environment.\n",
        "        done (bool): Whether the episode is done.\n",
        "        info (dict): Information about the game state.\n",
        "\n",
        "    Returns:\n",
        "        float: The custom reward.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get coordinates of objects (replace with logic specific to the game)\n",
        "    ball_x = info.get(\"ball_x\", 0)  # Replace \"ball_x\" with the actual key in 'info'\n",
        "    ball_y = info.get(\"ball_y\", 0)  # Replace \"ball_y\" with the actual key in 'info'\n",
        "    paddle_x = info.get(\"paddle_x\", 0)  # Replace \"paddle_x\" with the actual key in 'info'\n",
        "    paddle_y = info.get(\"paddle_y\", 0)  # Replace \"paddle_y\" with the actual key in 'info'\n",
        "\n",
        "    # Define events and calculate reward\n",
        "    ball_hits_paddle = abs(ball_x - paddle_x) < 5 and abs(ball_y - paddle_y) < 5\n",
        "    ball_missed = ball_x < paddle_x  # Ball passed the paddle\n",
        "    agent_moves_correctly = (ball_y - paddle_y) * info.get(\"paddle_velocity\", 0) > 0 # Paddle moving towards the ball\n",
        "\n",
        "    # Calculate reward\n",
        "    custom_reward = reward  # Start with the original reward\n",
        "\n",
        "    if ball_hits_paddle:\n",
        "        custom_reward += 0.1  # Small positive reward for hitting the ball\n",
        "\n",
        "    if ball_missed:\n",
        "        custom_reward -= 0.1  # Small penalty for missing\n",
        "\n",
        "    if agent_moves_correctly:\n",
        "        custom_reward += 0.05  # Encourage movement in the correct direction\n",
        "\n",
        "    return custom_reward\n"
      ],
      "metadata": {
        "id": "AlIich5UHs22"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Agent\n",
        "\n",
        "The training loop involves:\n",
        "\n",
        "- Collecting experience by interacting with the environment.\n",
        "- Storing experiences in a replay buffer.\n",
        "- Sampling from the buffer to train the DQN.\n",
        "- Runs multiple episodes where the agent interacts with the game.\n",
        "- Selects an action using the current policy.\n",
        "- Stores experiences and updates the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "asS3JfHdG0q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 7: Train the Agent\n",
        "\n",
        "num_episodes = 10\n",
        "batch_size = 8\n",
        "target_update_freq = 1\n",
        "episode_rewards = []\n",
        "\n",
        "# Training loop\n",
        "for episode in range(num_episodes):\n",
        "    state, _ = env.reset()\n",
        "    state = stack_frames(None, state, is_new=True) # Stack initial frames\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Choose action\n",
        "        state_tensor = torch.from_numpy(state).float().unsqueeze(0)  # Convert state to tensor and add batch dimension\n",
        "\n",
        "        if random.random() < epsilon:\n",
        "            action = env.action_space.sample() # Explore\n",
        "        else:\n",
        "          with torch.no_grad():  # Disable gradient calculation\n",
        "                action = torch.argmax(policy_net(state_tensor)).item()  # Exploit\n",
        "\n",
        "        # Take action\n",
        "        # The env.step() function now returns 5 values: observation, reward, terminated, truncated, info\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        next_state = stack_frames(state, next_state) # Stack new frame\n",
        "\n",
        "        # Use terminated or truncated to check if the episode is done\n",
        "        done = terminated or truncated\n",
        "\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        reward = custom_reward(obs, reward, done, info)\n",
        "\n",
        "\n",
        "        # Store in replay memory\n",
        "        replay_memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "        # Sample from replay memory and train\n",
        "        if len(replay_memory) > batch_size:\n",
        "            # ... (code to sample from replay memory, calculate Q-values, loss, etc.) ...\n",
        "            pass\n",
        "\n",
        "        state = next_state # Update state\n",
        "\n",
        "        # Update the total reward for the episode\n",
        "        total_reward += reward\n",
        "\n",
        "        # Update epsilon\n",
        "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
        "\n",
        "        # Update target network periodically\n",
        "        if episode % target_update_freq == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "      # Print total reward at the end of the episode\n",
        "    if episode % 1 == 0:\n",
        "        print(f\"Episode {episode}: Reward = {total_reward}, Epsilon = {epsilon:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tntBCd5yVei2",
        "outputId": "9e0a7c08-3615-4eee-923e-d21d7f422b0e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Reward = 30.900000000000244, Epsilon = 0.122\n",
            "Episode 1: Reward = 31.80000000000024, Epsilon = 0.050\n",
            "Episode 2: Reward = 30.300000000000217, Epsilon = 0.050\n",
            "Episode 3: Reward = 30.300000000000217, Epsilon = 0.050\n",
            "Episode 4: Reward = 30.400000000000237, Epsilon = 0.050\n",
            "Episode 5: Reward = 30.300000000000217, Epsilon = 0.050\n",
            "Episode 6: Reward = 27.300000000000175, Epsilon = 0.050\n",
            "Episode 7: Reward = 27.300000000000175, Epsilon = 0.050\n",
            "Episode 8: Reward = 27.300000000000175, Epsilon = 0.050\n",
            "Episode 9: Reward = 27.300000000000175, Epsilon = 0.050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Environment\n",
        "\n",
        "Finally, the script evaluates the trained agent and visualizes its performance using `matplotlib`.\n",
        "\n",
        "- Runs the trained model in the environment.\n",
        "- Displays the game frame-by-frame."
      ],
      "metadata": {
        "id": "QxeH2h98GmYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\")\n",
        "\n",
        "state, info = env.reset()\n",
        "for _ in range(100):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    try:\n",
        "       img = env.render()\n",
        "       if img is not None:\n",
        "           img = Image.fromarray(img)\n",
        "           ipythondisplay.display(img)\n",
        "           ipythondisplay.clear_output(wait=True)\n",
        "           time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "       print(f\"Error during rendering: {e}\")\n",
        "\n",
        "display.stop()\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "0rKkVc18Vegg",
        "outputId": "c2bdf2c6-f127-4090-d5d6-e07d41237ec2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAAE9ElEQVR4Ae3awU0bUQBF0TiigRSRDrKBPVIkWqAKCkEpghZYsYcNHaQFF5GsRkb+aIx8BXe+bpTFZGw/vf+ORiDI7ts7f/78/vHOK93e0gK7r4K8vrpcdnp6flmuZ7p4vbtZPc6v+8fV95zzhu/nfLjP+hcI2G90VsOAz5rP/+ELf8U5Gh5+rT3lazN16p5gaklpTsBSGKpWwNSS0pyApTBUrYCpJaU5AUthqFoBU0tKcwKWwlC1AqaWlOYELIWhagVMLSnN6WfRnwTzmT9/PjxST/DhGhNeBzwh6uGRAj5cY8LrL/s/WRNuqTxST7CShSsVMLelMmm33++VxSrFLNATzOyoTQlYS8MUC5jZUZsSsJaGKRYws6M2JWAtDVMsYGZHbUrAWhqmWMDMjtqUftmgpWGK9QQzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTAtbSMMUCZnbUpgSspWGKBczsqE0JWEvDFAuY2VGbErCWhikWMLOjNiVgLQ1TLGBmR21KwFoapljAzI7alIC1NEyxgJkdtSkBa2mYYgEzO2pTLrTNKrYs8Hp3s1z/un9crk+56Ak+ZaUNvyfgDeOdUj3gU1ba8HsC3jDeKdU//E3W9dXlkvv0/LJcd+FcoCfY6YK1CvjNlLcPf///fXNr4/8IeOOAa/UDXlto468HvHHAtfof/i56LXDbrz/c/tz2AY7a9wQfTTLXjYDn8jw6zW6/3x/d7MY8C/QEz2M5PEnAw1nmuRnwPJbDkwQ8nGWemwHPYzk8ScDDWea5GfA8lsOTBDycZZ6bAc9jOTxJwMNZ5rkZ8DyWw5MEPJxlnpsBz2M5PEnAw1nmuRnwPJbDk/wDvOUgOYFVL4AAAAAASUVORK5CYII=\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "This notebook implements a Deep Q-Network (DQN) to train an AI agent for Pong. It preprocesses game frames, defines a neural network, trains using reinforcement learning, and visualizes performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Octg2DAHB2Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZC5BslACFkxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}